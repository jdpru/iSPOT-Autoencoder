# iSPOT-Autoencoder ğŸ§ âš¡

**Semi-supervised learning for antidepressant treatment response prediction using EEG data**

## Overview ğŸ”

This project explores whether we can predict which patients will respond to antidepressant medications using brain activity patterns recorded via EEG. We use autoencoder architectures to learn meaningful latent representations from EEG signals, then feed these learned features into logistic regression models for treatment response prediction. ğŸ¯

## Dataset ğŸ“Š

This project uses data from the **iSPOT-D (International Study to Predict Optimized Treatment in Depression)** clinical trial, led by Dr. Leanne Williams at Stanford University. iSPOT-D is a landmark study that collected comprehensive neurophysiological and clinical data to advance personalized medicine for depression treatment. ğŸ¥

- **694 patients** total (594 training, 100 test) ğŸ‘¥
- **3 antidepressant treatments**: Escitalopram, Sertraline, Venlafaxine XR ğŸ’Š
- **Binary outcome**: Treatment response (responder/non-responder) âœ…âŒ
- **EEG features**: 26 scalp electrodes Ã— 116 timepoints = 3,016 features per patient ğŸ”¬
  - Each electrode records 116 seconds at 500 Hz sampling rate
  - Broadband power calculated per second

*We gratefully acknowledge Dr. Leanne Williams and the iSPOT-D research team for making this valuable dataset available for advancing computational psychiatry research.* 

## Approach ğŸš€

### 1. Baseline: Unsupervised Autoencoder ğŸ”„
- Standard encoder-decoder architecture
- Learns latent representations using only reconstruction loss
- Latent features â†’ Logistic regression â†’ Response prediction

### 2. Main Model: Semi-supervised Autoencoder âš¡
- **Dual-head architecture**: Decoder + Predictor heads ğŸ”€
- **Dual loss function**: 
  - Reconstruction loss (MSE) from decoder
  - Binary cross-entropy loss from predictor head
- Both losses backpropagate to inform the same latent space ğŸ”
- Latent features â†’ Logistic regression â†’ Response prediction

### 3. Advanced Model: Semi-supervised Recurrent VAE (RVAE) ğŸŒŸ
- Incorporates temporal structure with GRU layers â°
- Variational approach with KL divergence regularization
- Same dual-supervision strategy as above

## Key Features âœ¨

- **Hyperparameter search** for all model architectures ğŸ”
- **Cross-validation** with proper train/validation splits ğŸ“ˆ
- **Multiple baselines**: Clinical features only, EEG only, combined features ğŸ“Š
- **Evaluation metrics**: ROC-AUC, accuracy, sensitivity, specificity ğŸ“
- **Visualization**: Confusion matrices and model comparisons ğŸ“‰

## Project Structure

```
src/
â”œâ”€â”€ configs/           # Configuration files and hyperparameters
â”œâ”€â”€ data/             # Data loading and preprocessing utilities  
â”œâ”€â”€ models/           # Autoencoder architectures
â”œâ”€â”€ training/         # Training loops for different models
â”œâ”€â”€ hyperparam_search/ # Grid search implementations
â”œâ”€â”€ experiments.py    # Main experimental pipeline
â””â”€â”€ main.py          # Entry point
```

## Usage ğŸ› ï¸

1. **Run hyperparameter search** (optional, pre-trained models available) ğŸ”§:
   ```bash
   python src/hyperparam_search/run.py
   ```

2. **Run all experiments** ğŸ§ª:
   ```bash
   python src/main.py
   ```

This will evaluate all model variants and generate performance comparisons. ğŸ“Š

## Dependencies ğŸ“¦

- PyTorch ğŸ”¥
- scikit-learn ğŸ¤–
- pandas ğŸ¼
- numpy ğŸ”¢
- matplotlib ğŸ“ˆ
- seaborn ğŸŒŠ

See `environment.yml` for full environment setup. âš™ï¸
